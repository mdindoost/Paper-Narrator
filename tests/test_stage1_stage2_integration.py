#!/usr/bin/env python3
"""
Test Stage 1 + Stage 2 Integration
Save as: test_stage1_stage2_integration.py (in root directory)

Tests the complete two-stage analysis:
1. Stage 1: Core Understanding (Title + Abstract + Conclusion + Future Works)
2. Stage 2: Evidence Hunting (Full paper analysis with claim-evidence mapping)
"""

import sys
import os
from pathlib import Path

# Add src directory to path
sys.path.append('src')
sys.path.append('.')

# Import components
try:
    from pdf_processor import PDFProcessor
    from enhanced_analyzer import EnhancedPaperAnalyzer
    from stage2_evidence_hunter import Stage2EvidenceHunter
except ImportError as e:
    print(f"âŒ Import error: {e}")
    print("Make sure you have:")
    print("  - pdf_processor.py in src/")
    print("  - enhanced_analyzer.py in current directory")
    print("  - stage2_evidence_hunter.py in src/")
    sys.exit(1)


def test_complete_two_stage_analysis(pdf_path: str):
    """Test complete Stage 1 + Stage 2 analysis pipeline"""
    
    print("ğŸš€ COMPLETE TWO-STAGE ANALYSIS TEST")
    print("Stage 1: Core Understanding â†’ Stage 2: Evidence Hunting")
    print("=" * 80)
    
    pdf_file = Path(pdf_path)
    if not pdf_file.exists():
        print(f"âŒ PDF not found: {pdf_path}")
        return False
    
    print(f"ğŸ“„ Analyzing: {pdf_file.name}")
    
    # Initialize all processors
    pdf_processor = PDFProcessor()
    stage1_analyzer = EnhancedPaperAnalyzer()
    stage2_hunter = Stage2EvidenceHunter()
    
    # Test connections
    if not stage1_analyzer.test_connection():
        print("âŒ Ollama connection failed for Stage 1")
        return False
    
    if not stage2_hunter.test_connection():
        print("âŒ Ollama connection failed for Stage 2")
        return False
    
    print("âœ… All connections successful")
    
    try:
        # ================== STAGE 1: CORE UNDERSTANDING ==================
        print(f"\n{'='*20} STAGE 1: CORE UNDERSTANDING {'='*20}")
        
        # Extract and process PDF
        print("ğŸ“– Extracting PDF content...")
        paper_data = pdf_processor.process_paper(pdf_path)
        raw_text = paper_data["raw_text"]
        print(f"âœ… Extracted {len(raw_text):,} characters")
        
        # Enhanced section detection
        print("\nğŸ” Stage 1: Detecting core sections...")
        core_sections = stage1_analyzer.enhanced_section_detection(raw_text)
        
        if not core_sections:
            print("âŒ No core sections found - cannot proceed")
            return False
        
        print(f"âœ… Found {len(core_sections)} core sections")
        for section, content in core_sections.items():
            print(f"   â€¢ {section}: {len(content)} characters")
        
        # Stage 1 comprehensive analysis
        print(f"\nğŸ§  Stage 1: Comprehensive core analysis...")
        core_understanding = stage1_analyzer.stage1_core_understanding_analysis(core_sections)
        
        # Display Stage 1 results
        print(f"\nğŸ“Š STAGE 1 RESULTS SUMMARY:")
        print(f"   ğŸ¯ Field: {core_understanding.field_classification}")
        print(f"   ğŸ“– Story elements: {len(core_understanding.research_story_arc)}")
        print(f"   ğŸ” Confidence factors: {len(core_understanding.confidence_assessment)}")
        print(f"   âš”ï¸ Debate points: {len(core_understanding.debate_seed_points)}")
        print(f"   ğŸ”§ Technical elements: {len(core_understanding.key_technical_elements)}")
        
        # ================== STAGE 2: EVIDENCE HUNTING ==================
        print(f"\n{'='*20} STAGE 2: EVIDENCE HUNTING {'='*20}")
        
        # Stage 2 comprehensive evidence analysis
        print("ğŸ” Stage 2: Comprehensive evidence hunting...")
        comprehensive_evidence = stage2_hunter.comprehensive_stage2_analysis(
            core_understanding, raw_text
        )
        
        # ================== DISPLAY COMPREHENSIVE RESULTS ==================
        print(f"\n{'='*20} COMPREHENSIVE ANALYSIS RESULTS {'='*20}")
        
        # Evidence Mappings
        print(f"\nğŸ“‹ EVIDENCE-CLAIM MAPPINGS ({len(comprehensive_evidence.evidence_mappings)}):")
        for i, mapping in enumerate(comprehensive_evidence.evidence_mappings, 1):
            print(f"\n   {i}. CLAIM: {mapping.claim[:80]}...")
            print(f"      EVIDENCE STRENGTH: {mapping.evidence_strength.upper()}")
            
            if mapping.supporting_evidence:
                print(f"      âœ… SUPPORTING ({len(mapping.supporting_evidence)}):")
                for evidence in mapping.supporting_evidence[:2]:
                    print(f"         â€¢ {evidence[:60]}...")
            
            if mapping.contradictory_evidence:
                print(f"      âŒ CONTRADICTORY ({len(mapping.contradictory_evidence)}):")
                for evidence in mapping.contradictory_evidence[:2]:
                    print(f"         â€¢ {evidence[:60]}...")
            
            if mapping.evidence_location:
                print(f"      ğŸ“ LOCATIONS: {', '.join(mapping.evidence_location[:3])}")
        
        # Technical Deep Dive
        tech = comprehensive_evidence.technical_deep_dive
        print(f"\nğŸ”¬ TECHNICAL DEEP DIVE:")
        print(f"   ğŸ§® Algorithms: {len(tech.algorithms_detailed)}")
        print(f"   ğŸ§ª Experimental Design: {len(tech.experimental_design)}")
        print(f"   ğŸ“Š Statistical Results: {len(tech.statistical_results)}")
        print(f"   ğŸ“ˆ Performance Metrics: {len(tech.performance_metrics)}")
        print(f"   ğŸ’» Implementation: {len(tech.implementation_details)}")
        print(f"   âš–ï¸ Comparisons: {len(tech.comparison_results)}")
        print(f"   âš ï¸ Limitations: {len(tech.limitations_detailed)}")
        
        # Show sample technical details
        if tech.algorithms_detailed:
            print(f"\n   ğŸ§® SAMPLE ALGORITHMS:")
            for alg in tech.algorithms_detailed[:2]:
                print(f"      â€¢ {alg[:80]}...")
        
        if tech.performance_metrics:
            print(f"\n   ğŸ“ˆ SAMPLE PERFORMANCE:")
            for metric in tech.performance_metrics[:2]:
                print(f"      â€¢ {metric[:80]}...")
        
        # Methodology Analysis
        method = comprehensive_evidence.methodology_analysis
        print(f"\nğŸ“ METHODOLOGY ANALYSIS:")
        print(f"   ğŸ“Š Data Collection: {len(method.data_collection)}")
        print(f"   ğŸ‘¥ Sample Info: {len(method.sample_characteristics)}")
        print(f"   ğŸ›ï¸ Controls: {len(method.control_measures)}")
        print(f"   âœ… Validation: {len(method.validation_approaches)}")
        print(f"   ğŸ“Š Statistical Methods: {len(method.statistical_methods)}")
        print(f"   âš ï¸ Potential Biases: {len(method.potential_biases)}")
        
        # Gaps and Overclaims
        print(f"\nğŸ” CRITICAL ANALYSIS:")
        print(f"   ğŸ“‰ Evidence Gaps: {len(comprehensive_evidence.claim_evidence_gaps)}")
        print(f"   ğŸ“¢ Potential Overclaims: {len(comprehensive_evidence.overclaim_detection)}")
        
        if comprehensive_evidence.claim_evidence_gaps:
            print(f"\n   ğŸ“‰ EVIDENCE GAPS:")
            for gap in comprehensive_evidence.claim_evidence_gaps[:3]:
                print(f"      â€¢ {gap[:80]}...")
        
        if comprehensive_evidence.overclaim_detection:
            print(f"\n   ğŸ“¢ POTENTIAL OVERCLAIMS:")
            for overclaim in comprehensive_evidence.overclaim_detection[:3]:
                print(f"      â€¢ {overclaim[:80]}...")
        
        # Debate Ammunition
        ammunition = comprehensive_evidence.expert_debate_ammunition
        print(f"\nâš”ï¸ EXPERT DEBATE AMMUNITION:")
        print(f"   ğŸ˜Š Optimist Points: {len(ammunition.get('optimist', []))}")
        print(f"   ğŸ¤¨ Skeptic Points: {len(ammunition.get('skeptic', []))}")
        
        if ammunition.get('optimist'):
            print(f"\n   ğŸ˜Š OPTIMIST AMMUNITION:")
            for point in ammunition['optimist'][:3]:
                print(f"      + {point[:70]}...")
        
        if ammunition.get('skeptic'):
            print(f"\n   ğŸ¤¨ SKEPTIC AMMUNITION:")
            for point in ammunition['skeptic'][:3]:
                print(f"      - {point[:70]}...")
        
        # ================== QUALITY ASSESSMENT ==================
        print(f"\n{'='*20} COMPREHENSIVE QUALITY ASSESSMENT {'='*20}")
        
        quality_score = 0
        max_score = 20
        
        # Stage 1 quality
        if core_understanding.field_classification != "General Research":
            quality_score += 2
            print("   âœ… Specific field identified (+2)")
        
        if len(core_understanding.debate_seed_points) >= 8:
            quality_score += 3
            print("   âœ… Excellent Stage 1 debate depth (+3)")
        elif len(core_understanding.debate_seed_points) >= 5:
            quality_score += 2
            print("   âœ… Good Stage 1 debate coverage (+2)")
        
        # Stage 2 quality
        if len(comprehensive_evidence.evidence_mappings) >= 3:
            quality_score += 3
            print("   âœ… Multiple evidence mappings (+3)")
        
        strong_evidence_count = sum(1 for m in comprehensive_evidence.evidence_mappings if m.evidence_strength == 'strong')
        if strong_evidence_count >= 1:
            quality_score += 2
            print(f"   âœ… Strong evidence found ({strong_evidence_count} claims) (+2)")
        
        if len(tech.algorithms_detailed) + len(tech.performance_metrics) >= 4:
            quality_score += 3
            print("   âœ… Comprehensive technical analysis (+3)")
        
        if len(method.potential_biases) + len(comprehensive_evidence.claim_evidence_gaps) >= 3:
            quality_score += 2
            print("   âœ… Critical analysis with gaps/biases identified (+2)")
        
        if len(ammunition.get('optimist', [])) >= 3 and len(ammunition.get('skeptic', [])) >= 3:
            quality_score += 3
            print("   âœ… Balanced debate ammunition generated (+3)")
        
        # Bonus for sophisticated analysis
        if any('statistical' in str(item).lower() for item in [tech.statistical_results, method.statistical_methods]):
            quality_score += 2
            print("   âœ… Statistical sophistication detected (+2)")
        
        print(f"\nğŸ† COMPREHENSIVE QUALITY SCORE: {quality_score}/{max_score}")
        
        if quality_score >= 15:
            print("ğŸŒŸ OUTSTANDING - Maximum depth achieved, ready for expert debates!")
        elif quality_score >= 12:
            print("âœ… EXCELLENT - High quality two-stage analysis, ready for debates!")
        elif quality_score >= 8:
            print("âš ï¸ GOOD - Solid analysis, minor improvements possible")
        else:
            print("âŒ NEEDS IMPROVEMENT - Enhance prompts or check paper complexity")
        
        # Final summary
        print(f"\nğŸ¯ ANALYSIS COMPLETENESS:")
        print(f"   Stage 1: Core understanding âœ… ({len(core_understanding.debate_seed_points)} debate points)")
        print(f"   Stage 2: Evidence hunting âœ… ({len(comprehensive_evidence.evidence_mappings)} claim mappings)")
        print(f"   Technical depth: {'âœ… Excellent' if len(tech.algorithms_detailed) + len(tech.performance_metrics) >= 4 else 'âš ï¸ Moderate'}")
        print(f"   Debate readiness: {'âœ… Ready' if quality_score >= 12 else 'âš ï¸ Needs work'}")
        
        return quality_score >= 8
        
    except Exception as e:
        print(f"âŒ Error during two-stage analysis: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Main test function"""
    
    print("ğŸš€ AI Paper Narrator - Complete Two-Stage Analysis Test")
    print("Testing Enhanced Stage 1 + Stage 2 Evidence Hunting")
    print("-" * 80)
    
    # Default paper path
    default_path = "/home/md724/ai_paper_narrator/data/input/WCC_and_CM_Paper_Complex_Networks-1.pdf"
    
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
    else:
        pdf_path = default_path
    
    print(f"ğŸ“„ Testing with: {pdf_path}")
    
    success = test_complete_two_stage_analysis(pdf_path)
    
    if success:
        print(f"\nğŸ‰ TWO-STAGE ANALYSIS SUCCESSFUL!")
        print(f"âœ… Stage 1: Core understanding with comprehensive debate points")
        print(f"âœ… Stage 2: Evidence hunting with claim-evidence mapping")
        print(f"âœ… Technical deep dive with expert-level details")
        print(f"âœ… Methodology analysis with bias detection")
        print(f"âœ… Debate ammunition for optimist vs skeptic discussions")
        print(f"\nğŸš€ READY FOR STAGE 3: SOPHISTICATED DEBATE GENERATION")
    else:
        print(f"\nğŸ”§ TWO-STAGE ANALYSIS NEEDS IMPROVEMENT")
        print(f"âŒ Check quality assessment above for specific issues")
        print(f"ğŸ” Debug individual stages before proceeding")


if __name__ == "__main__":
    main()
